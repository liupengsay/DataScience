{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 利用sprase矩阵进行文本特征提取\n",
    "## 从原始数据输入到特征文件生成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0.引入三方库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy import sparse\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.读取所需数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('data/train.csv')\n",
    "test =  pd.read_csv('data/test.csv')\n",
    "merchant = pd.read_csv('data/merchants.csv')\n",
    "new_transaction = pd.read_csv('data/new_merchant_transactions.csv')\n",
    "history_transaction = pd.read_csv('data/historical_transactions.csv')\n",
    "transaction = pd.concat([new_transaction, history_transaction], axis=0, ignore_index=True)\n",
    "del new_transaction\n",
    "del history_transaction\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.做数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merchant_id\n",
      "merchant_category_id\n",
      "state_id\n",
      "subsector_id\n",
      "city_id\n"
     ]
    }
   ],
   "source": [
    "nlp_features = ['merchant_id', 'merchant_category_id', 'state_id', 'subsector_id', 'city_id']\n",
    "\n",
    "for co in nlp_features:\n",
    "    print(co)\n",
    "    transaction[co] = transaction[co].astype(str)\n",
    "    temp = transaction[transaction['month_lag']>=0].groupby(\"card_id\")[co].apply(list).apply(lambda x:' '.join(x)).reset_index()\n",
    "    temp.columns = ['card_id', co+'_new']\n",
    "    train = pd.merge(train, temp, how='left', on='card_id')\n",
    "    test = pd.merge(test, temp, how='left', on='card_id')\n",
    "\n",
    "    temp = transaction[transaction['month_lag']<0].groupby(\"card_id\")[co].apply(list).apply(lambda x:' '.join(x)).reset_index()\n",
    "    temp.columns = ['card_id', co+'_hist']\n",
    "    train = pd.merge(train, temp, how='left', on='card_id')\n",
    "    test = pd.merge(test, temp, how='left', on='card_id')\n",
    "\n",
    "    temp = transaction.groupby(\"card_id\")[co].apply(list).apply(lambda x:' '.join(x)).reset_index()\n",
    "    temp.columns = ['card_id', co+'_all']\n",
    "    train = pd.merge(train, temp, how='left', on='card_id').fillna(\"-1\")\n",
    "    test = pd.merge(test, temp, how='left', on='card_id').fillna(\"-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.进行特征提取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merchant_id_new\n",
      "merchant_id_hist\n",
      "merchant_id_all\n",
      "merchant_category_id_new\n",
      "merchant_category_id_hist\n",
      "merchant_category_id_all\n",
      "state_id_new\n",
      "state_id_hist\n",
      "state_id_all\n",
      "subsector_id_new\n",
      "subsector_id_hist\n",
      "subsector_id_all\n",
      "city_id_new\n",
      "city_id_hist\n",
      "city_id_all\n"
     ]
    }
   ],
   "source": [
    "train_x = pd.DataFrame()\n",
    "test_x = pd.DataFrame()\n",
    "\n",
    "cntv = CountVectorizer()\n",
    "\n",
    "tfv = TfidfVectorizer(ngram_range=(1, 2), min_df=3, max_df=0.9, use_idf=1, smooth_idf=1, sublinear_tf=1)\n",
    "    \n",
    "    \n",
    "vector_feature =[]\n",
    "for co in ['merchant_id', 'merchant_category_id', 'state_id', 'subsector_id', 'city_id']:\n",
    "    vector_feature.extend([co+'_new', co+'_hist', co+'_all'])\n",
    "for feature in vector_feature:\n",
    "    print(feature)\n",
    "    cntv.fit(train[feature].append(test[feature]))\n",
    "    train_x = sparse.hstack((train_x, cntv.transform(train[feature]))).tocsr()\n",
    "    test_x = sparse.hstack((test_x, cntv.transform(test[feature]))).tocsr()\n",
    "    \n",
    "    tfv.fit(train[feature].append(test[feature]))\n",
    "    train_x = sparse.hstack((train_x, cntv.transform(train[feature]))).tocsr()\n",
    "    test_x = sparse.hstack((test_x, cntv.transform(test[feature]))).tocsr()\n",
    "sparse.save_npz(\"preprocess/train_nlp.npz\", train_x)\n",
    "sparse.save_npz(\"preprocess/test_nlp.npz\", test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(201917, 1846286)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
