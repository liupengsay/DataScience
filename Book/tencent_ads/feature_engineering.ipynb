{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 特征工程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train = pd.read_csv('preprocess/train_sample.csv')\n",
    "test = pd.read_csv('preprocess/test_sample.csv')\n",
    "\n",
    "text_features = ['appIdAction', 'appIdInstall', 'ct', 'interest1',\n",
    " 'interest2', 'interest3', 'interest4', 'interest5', 'kw1',\n",
    " 'kw2', 'kw3', 'marriageStatus', 'os', 'topic1', 'topic2', 'topic3']\n",
    "cat_features = ['LBS', 'adCategoryId', 'advertiserId', 'age', 'campaignId',\n",
    " 'carrier', 'consumptionAbility', 'creativeId', 'creativeSize', 'education',\n",
    " 'gender', 'house', 'productId', 'productType']\n",
    "\n",
    "truth_test = pd.read_csv('preprocess/test_truth_sample.csv')['label'].values\n",
    "\n",
    "train_df = pd.DataFrame()\n",
    "test_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.通用特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exposure\n",
    "## 一维曝光度\n",
    "for feature in cat_features:\n",
    "    se = train[feature].append(test[feature]).value_counts()\n",
    "    train_df['exposure_' + feature] = train[feature].map(se).fillna(0).astype(int).values\n",
    "    test_df['exposure_' + feature] = test[feature].map(se).fillna(0).astype(int).values\n",
    "    \n",
    "## 二维曝光度\n",
    "n = len(cat_features)\n",
    "for i in range(n-1):\n",
    "    for j in range(i+1, n):\n",
    "        col_name = \"exposure_\"+cat_features[i]+\"_and_\"+cat_features[j]\n",
    "        cols = [cat_features[i],cat_features[j]]\n",
    "        stat = train.append(test).groupby(cols).size().reset_index()\n",
    "        stat.columns = cols + [col_name]\n",
    "        \n",
    "        train_df[col_name] = pd.merge(train[cols],stat,how='left',on=cols)[col_name].fillna(0).astype(int).values\n",
    "        test_df[col_name] = pd.merge(test[cols],stat,how='left',on=cols)[col_name].fillna(0).astype(int).values\n",
    "# nunique\n",
    "num = 0\n",
    "for i in range(n):\n",
    "    for j in range(n):\n",
    "        if i!=j:\n",
    "            col_name = \"nunique_\"+cat_features[j]+\"_in_\"+cat_features[i]\n",
    "            se = train.append(test).groupby([cat_features[i]])[cat_features[j]].value_counts()\n",
    "            se = pd.Series(1,index=se.index).sum(level=cat_features[i])\n",
    "            \n",
    "            train_df[col_name] = (train[cat_features[i]].map(se)).fillna(value=0).values\n",
    "            test_df[col_name] = (test[cat_features[i]].map(se)).fillna(value=0).values\n",
    "\n",
    "# ratio\n",
    "for i in range(n-1):\n",
    "    for j in range(i+1, n):\n",
    "            col_both = \"exposure_\"+cat_features[i]+\"_and_\"+cat_features[j]\n",
    "            \n",
    "            col_one = \"exposure_\"+cat_features[j]\n",
    "            col_name = \"ratio_exposure_\"+cat_features[i]+\"_in_\"+cat_features[j]\n",
    "            train_df[col_name] = train_df[col_both]/train_df[col_one]\n",
    "            test_df[col_name] = test_df[col_both]/test_df[col_one]\n",
    "            \n",
    "            col_one = \"exposure_\"+cat_features[i]\n",
    "            col_name = \"ratio_exposure_\"+cat_features[j]+\"_in_\"+cat_features[i]\n",
    "            train_df[col_name] = train_df[col_both]/train_df[col_one]\n",
    "            test_df[col_name] = test_df[col_both]/test_df[col_one]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.业务特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ctr (进阶版本可有贝叶斯平滑）\n",
    "n_parts = 5\n",
    "train['part'] = (pd.Series(train.index)%n_parts).values\n",
    "\n",
    "## 一阶ctr\n",
    "for co in cat_features:\n",
    "    col_name = 'ctr_of_'+co\n",
    "    ctr_train = pd.Series(dtype=float)\n",
    "    ctr_test = pd.Series(0, index=test.index.tolist())\n",
    "    for i in range(n_parts):\n",
    "        se = train[train['part']!=i].groupby(co)['label'].mean()\n",
    "        ctr_train = ctr_train.append(train[train['part']==i][co].map(se))\n",
    "        ctr_test += test[co].map(se)\n",
    "    \n",
    "    train_df[col_name] = ctr_train.sort_index().fillna(-1).values\n",
    "    test_df[col_name] = (ctr_test/5).fillna(-1).values\n",
    "\n",
    "## 二阶ctr\n",
    "for i in range(n-1):\n",
    "    for j in range(i+1, n):\n",
    "        col_name = 'ctr_of_'+cat_features[i]+\"_and_\"+cat_features[j]\n",
    "        cols = [cat_features[i], cat_features[j]]\n",
    "        ctr_train = pd.Series(dtype=float)\n",
    "        ctr_test = pd.Series(0, index=test.index.tolist())\n",
    "\n",
    "        for k in range(n_parts):\n",
    "            stat = train[train['part']!=k].groupby(cols)['label'].mean().reset_index()\n",
    "            stat.columns = cols + [col_name]\n",
    "            \n",
    "            se = pd.merge(train[train['part']==k][cols],stat,how='left',on=cols)[col_name]\n",
    "            ctr_train = ctr_train.append(pd.Series(se.values, index=train[train['part']==k].index.tolist()))\n",
    "            ctr_test += pd.merge(test[cols],stat,how='left',on=cols)[col_name]\n",
    "        train_df[col_name] = ctr_train.sort_index().fillna(-1).values\n",
    "        test_df[col_name] = (ctr_test/5).fillna(-1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(87988, 574)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22660, 574)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.文本特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder,LabelEncoder\n",
    "train_sp = pd.DataFrame()\n",
    "test_sp = pd.DataFrame()\n",
    "\n",
    "def change_stop_words(se):\n",
    "    return se.apply(lambda x: 'stop '+x)\n",
    "\n",
    "\n",
    "# stop words\n",
    "for feature in text_features:\n",
    "    train[feature] = change_stop_words(train[feature])\n",
    "    test[feature] = change_stop_words(test[feature])\n",
    "\n",
    "# labelencoder\n",
    "lab = LabelEncoder()\n",
    "for feature in cat_features:\n",
    "    lab.fit(train[feature].append(test[feature]))\n",
    "    \n",
    "    train_df['labelencoder_'+feature] = lab.transform(train[feature])\n",
    "    test_df['labelencoder_'+feature] = lab.transform(test[feature])\n",
    "\n",
    "# onehot\n",
    "ohe = OneHotEncoder()\n",
    "for feature in cat_features:\n",
    "    ohe.fit(train[feature].append(test[feature]).values.reshape(-1, 1))\n",
    "    \n",
    "    arr = ohe.transform(train[feature].values.reshape(-1, 1))\n",
    "    train_sp = sparse.hstack((train_sp, arr))\n",
    "    \n",
    "    arr = ohe.transform(test[feature].values.reshape(-1, 1))\n",
    "    test_sp = sparse.hstack((test_sp, arr))\n",
    "\n",
    "# countvectorizer\n",
    "cntv=CountVectorizer()\n",
    "for feature in text_features:\n",
    "    cntv.fit(train[feature].append(test[feature]))\n",
    "    \n",
    "    train_sp = sparse.hstack((train_sp, cntv.transform(train[feature])))\n",
    "    test_sp = sparse.hstack((test_sp, cntv.transform(test[feature])))\n",
    "\n",
    "# tf-idf\n",
    "tfd = TfidfVectorizer()\n",
    "for feature in text_features:\n",
    "    tfd.fit(train[feature].append(test[feature]))\n",
    "    \n",
    "    train_sp = sparse.hstack((train_sp, tfd.transform(train[feature])))\n",
    "    test_sp = sparse.hstack((test_sp, tfd.transform(test[feature])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(87988, 250053)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22660, 250053)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.特征降维"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 稀疏特征降维 TruncatedSVD\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from scipy.sparse import random as sparse_random\n",
    "from sklearn.random_projection import sparse_random_matrix\n",
    "svd = TruncatedSVD(n_components=100, n_iter=50, random_state=2020)\n",
    "svd.fit(sparse.vstack((train_sp, test_sp)))\n",
    "\n",
    "cols = ['svd_'+str(k) for k in range(100)]\n",
    "\n",
    "train_svd = pd.DataFrame(svd.transform(train_sp), columns = cols)\n",
    "test_svd = pd.DataFrame(svd.transform(test_sp), columns = cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.存储特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse.save_npz(\"preprocess/train_sample_sparse.npz\",train_sp)\n",
    "sparse.save_npz(\"preprocess/test_sample_sparse.npz\",test_sp)\n",
    "\n",
    "train_df.to_csv(\"preprocess/train_sample_feature.csv\", index=False)\n",
    "test_df.to_csv(\"preprocess/test_sample_feature.csv\", index=False)\n",
    "\n",
    "train_svd.to_csv(\"preprocess/train_sample_svd.csv\", index=False)\n",
    "test_svd.to_csv(\"preprocess/test_sample_svd.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
